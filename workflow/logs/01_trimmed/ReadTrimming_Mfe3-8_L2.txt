Path to Cutadapt set as: 'cutadapt' (default)
Cutadapt seems to be working fine (tested command 'cutadapt --version')
Cutadapt version: 5.0
Could not detect version of Python used by Cutadapt from the first line of Cutadapt (but found this: >>>#!/bin/sh<<<)
Letting the (modified) Cutadapt deal with the Python version instead
pigz 2.8
Parallel gzip (pigz) detected. Proceeding with multicore (de)compression using 7 cores

igzip command line interface 2.31.1
igzip detected. Using igzip for decompressing

Output will be written into the directory: /work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/01_trimmed/
Using user-specified basename (>>Mfe3-8_L2<<) instead of deriving the filename from the input file(s)


AUTO-DETECTING ADAPTER TYPE
===========================
Attempting to auto-detect adapter type from the first 1 million sequences of the first file (>> /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz <<)

Found perfect matches for the following adapter sequences:
Adapter type	Count	Sequence	Sequences analysed	Percentage
Nextera	508392	CTGTCTCTTATA	1000000	50.84
smallRNA	14	TGGAATTCTCGG	1000000	0.00
Illumina	1	AGATCGGAAGAGC	1000000	0.00
Using Nextera adapter for trimming (count: 508392). Second best hit was smallRNA (count: 14)

Writing report to '/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/01_trimmed/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.10
Cutadapt version: 5.0
Python version: could not detect
Number of cores used for trimming: 7
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Maximum number of tolerated Ns: 1
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 80 bp
Running FastQC on the data once trimming has completed
Running FastQC with the following extra arguments: '--outdir /work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/01_trimmed/fastqc_trimmed/'
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 5.0). Setting -j 7
Writing final adapter and quality trimmed output to Mfe3-8_L2_R1_001_5oUxvlehZJIf_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz <<< 
10000000 sequences processed
20000000 sequences processed
This is cutadapt 5.0 with Python 3.12.9
Command line parameters: -j 7 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz
Processing single-end reads on 7 cores ...

=== Summary ===

Total reads processed:              21,582,420
Reads with adapters:                13,982,789 (64.8%)
Reads written (passing filters):    21,582,420 (100.0%)

Total basepairs processed: 3,258,945,420 bp
Quality-trimmed:               1,968,469 bp (0.1%)
Total written (filtered):  2,662,580,834 bp (81.7%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 13982789 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 15.1%
  C: 34.3%
  G: 23.0%
  T: 27.6%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	2005290	5395605.0	0	2005290
2	608218	1348901.2	0	608218
3	185475	337225.3	0	185475
4	136155	84306.3	0	136155
5	108818	21076.6	0	108818
6	106361	5269.1	0	106361
7	98179	1317.3	0	98179
8	91747	329.3	0	91747
9	89671	82.3	0	89481 190
10	91408	20.6	1	88097 3311
11	94466	5.1	1	90944 3522
12	99383	1.3	1	95199 4184
13	102679	1.3	1	98558 4121
14	106242	1.3	1	102094 4148
15	110625	1.3	1	106648 3977
16	110926	1.3	1	107136 3790
17	116023	1.3	1	111710 4313
18	89883	1.3	1	87545 2338
19	96709	1.3	1	93512 3197
20	89642	1.3	1	86840 2802
21	94309	1.3	1	91080 3229
22	97927	1.3	1	94893 3034
23	101439	1.3	1	97382 4057
24	110509	1.3	1	106302 4207
25	118357	1.3	1	113686 4671
26	127203	1.3	1	122085 5118
27	114448	1.3	1	110817 3631
28	110583	1.3	1	107282 3301
29	103840	1.3	1	100758 3082
30	100797	1.3	1	97667 3130
31	100524	1.3	1	97232 3292
32	107206	1.3	1	103715 3491
33	115302	1.3	1	111291 4011
34	130836	1.3	1	125632 5204
35	121041	1.3	1	117791 3250
36	132810	1.3	1	128501 4309
37	133111	1.3	1	128933 4178
38	126648	1.3	1	122789 3859
39	111499	1.3	1	108572 2927
40	105210	1.3	1	102333 2877
41	104936	1.3	1	101779 3157
42	104860	1.3	1	102077 2783
43	115874	1.3	1	112152 3722
44	137762	1.3	1	132856 4906
45	113932	1.3	1	111126 2806
46	177422	1.3	1	170897 6525
47	104793	1.3	1	102040 2753
48	137884	1.3	1	133767 4117
49	126318	1.3	1	122975 3343
50	99929	1.3	1	97932 1997
51	114096	1.3	1	110736 3360
52	104211	1.3	1	101880 2331
53	128257	1.3	1	124128 4129
54	132905	1.3	1	128810 4095
55	129153	1.3	1	125645 3508
56	148091	1.3	1	143119 4972
57	146023	1.3	1	142001 4022
58	148807	1.3	1	144582 4225
59	132873	1.3	1	129646 3227
60	122463	1.3	1	119250 3213
61	111158	1.3	1	108310 2848
62	103453	1.3	1	101003 2450
63	116856	1.3	1	113542 3314
64	123988	1.3	1	120731 3257
65	136916	1.3	1	133007 3909
66	142904	1.3	1	138903 4001
67	145055	1.3	1	141301 3754
68	145620	1.3	1	141932 3688
69	134341	1.3	1	131104 3237
70	126289	1.3	1	123266 3023
71	98514	1.3	1	96553 1961
72	103368	1.3	1	100956 2412
73	107015	1.3	1	104598 2417
74	120469	1.3	1	117487 2982
75	128573	1.3	1	125026 3547
76	140793	1.3	1	136848 3945
77	136358	1.3	1	132583 3775
78	139009	1.3	1	134964 4045
79	134473	1.3	1	130867 3606
80	116309	1.3	1	113635 2674
81	103637	1.3	1	101254 2383
82	94419	1.3	1	92172 2247
83	94230	1.3	1	91944 2286
84	98346	1.3	1	96086 2260
85	124811	1.3	1	121317 3494
86	132436	1.3	1	128409 4027
87	153177	1.3	1	147510 5667
88	124716	1.3	1	120962 3754
89	142842	1.3	1	137530 5312
90	128344	1.3	1	124681 3663
91	118330	1.3	1	114990 3340
92	87607	1.3	1	85590 2017
93	87994	1.3	1	85933 2061
94	88206	1.3	1	86389 1817
95	92114	1.3	1	90296 1818
96	105774	1.3	1	103619 2155
97	67664	1.3	1	66379 1285
98	27970	1.3	1	27483 487
99	22952	1.3	1	22542 410
100	70208	1.3	1	68719 1489
101	41076	1.3	1	40410 666
102	16006	1.3	1	15634 372
103	4996	1.3	1	4636 360
104	4993	1.3	1	4536 457
105	5823	1.3	1	5264 559
106	7729	1.3	1	6911 818
107	7880	1.3	1	7029 851
108	6935	1.3	1	6223 712
109	5416	1.3	1	4920 496
110	10790	1.3	1	9806 984
111	3278	1.3	1	2851 427
112	6708	1.3	1	6064 644
113	6248	1.3	1	5722 526
114	3347	1.3	1	2981 366
115	4821	1.3	1	4394 427
116	8896	1.3	1	8282 614
117	3716	1.3	1	3331 385
118	2782	1.3	1	2449 333
119	4742	1.3	1	4436 306
120	2126	1.3	1	1918 208
121	4510	1.3	1	4212 298
122	2339	1.3	1	2134 205
123	3798	1.3	1	3573 225
124	1250	1.3	1	1116 134
125	560	1.3	1	444 116
126	150	1.3	1	74 76
127	203	1.3	1	97 106
128	105	1.3	1	38 67
129	91	1.3	1	21 70
130	105	1.3	1	32 73
131	94	1.3	1	12 82
132	107	1.3	1	26 81
133	86	1.3	1	7 79
134	79	1.3	1	8 71
135	82	1.3	1	4 78
136	86	1.3	1	3 83
137	79	1.3	1	1 78
138	53	1.3	1	4 49
139	108	1.3	1	1 107
140	71	1.3	1	0 71
141	142	1.3	1	3 139
142	94	1.3	1	7 87
143	388	1.3	1	8 380
144	40	1.3	1	0 40
145	136	1.3	1	6 130
146	31	1.3	1	0 31
147	73	1.3	1	0 73
148	164	1.3	1	0 164
149	69	1.3	1	2 67
150	36	1.3	1	0 36
151	26	1.3	1	0 26

RUN STATISTICS FOR INPUT FILE: /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R1_001_5oUxvlehZJIf.fastq.gz
=============================================
21582420 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Writing report to '/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/01_trimmed/Mfe3-8_L2_R2_001_oNc47QohBUMb.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R2_001_oNc47QohBUMb.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.10
Cutadapt version: 5.0
Python version: could not detect
Number of cores used for trimming: 7
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Maximum number of tolerated Ns: 1
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 80 bp
Running FastQC on the data once trimming has completed
Running FastQC with the following extra arguments: '--outdir /work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/01_trimmed/fastqc_trimmed/'
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 5.0). Setting -j -j 7
Writing final adapter and quality trimmed output to Mfe3-8_L2_R2_001_oNc47QohBUMb_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R2_001_oNc47QohBUMb.fastq.gz <<< 
10000000 sequences processed
This is cutadapt 5.0 with Python 3.12.9
Command line parameters: -j 7 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA /scratch/gsartonl/metagenomics/00_data/Mfe3-8_L2_R2_001_oNc47QohBUMb.fastq.gz
Processing single-end reads on 7 cores ...
Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Traceback (most recent call last):
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 104, in run
    for index, chunks in enumerate(self._read_chunks(*files)):
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/cutadapt/runners.py", line 118, in _read_chunks
    for chunk in dnaio.read_chunks(files[0], self.buffer_size):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/site-packages/dnaio/chunks.py", line 138, in read_chunks
    bufend = f.readinto(memoryview(buf)[start:]) + start  # type: ignore
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/FAC/FBM/DMF/pengel/spirit/gsartonl/metagenomics/workflow/.snakemake/conda/00ef20294fb16b16f34dc4887e97bf47_/lib/python3.12/gzip.py", line 324, in read
    return self._buffer.read(size)
           ^^^^^^^^^^^^^^^^^^^^^^^
EOFError: Compressed file ended before the end-of-stream marker was reached

Compressed file ended before the end-of-stream marker was reached


Cutadapt terminated with exit signal: '256'.
Terminating Trim Galore run, please check error message(s) to get an idea what went wrong...

